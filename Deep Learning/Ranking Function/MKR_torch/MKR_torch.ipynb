{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "from torch.utils.data import DataLoader,Sampler,Dataset,TensorDataset\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# # movie\n",
    "# parser.add_argument('--dataset', type=str, default='movie', help='which dataset to use')\n",
    "# parser.add_argument('--n_epochs', type=int, default=20, help='the number of epochs')\n",
    "# parser.add_argument('--dim', type=int, default=8, help='dimension of user and entity embeddings')\n",
    "# parser.add_argument('--L', type=int, default=1, help='number of low layers')\n",
    "# parser.add_argument('--H', type=int, default=1, help='number of high layers')\n",
    "# parser.add_argument('--batch_size', type=int, default=4096, help='batch size')\n",
    "# parser.add_argument('--l2_weight', type=float, default=1e-6, help='weight of l2 regularization')\n",
    "# parser.add_argument('--lr_rs', type=float, default=0.02, help='learning rate of RS task')\n",
    "# parser.add_argument('--lr_kge', type=float, default=0.01, help='learning rate of KGE task')\n",
    "# parser.add_argument('--kge_interval', type=int, default=3, help='training interval of KGE task')\n",
    "class args_instance:\n",
    "    def __init__(self):\n",
    "        self.dataset = \"music\"\n",
    "        self.n_epochs = 20\n",
    "        self.dim=8\n",
    "        self.L=1\n",
    "        self.H=1\n",
    "        self.batch_size=4096\n",
    "        self.l2_weight=1e-6\n",
    "        self.lr_rs = 0.02\n",
    "        self.lr_kge = 0.01\n",
    "        self.kge_interval=3\n",
    "args = args_instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading rating file ...\n",
      "splitting dataset ...\n",
      "reading KG file ...\n",
      "data loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def load_data(args):\n",
    "    n_user, n_item, train_data, eval_data, test_data = load_rating(args)\n",
    "    n_entity, n_relation, kg = load_kg(args)\n",
    "    print('data loaded.')\n",
    "\n",
    "    return n_user, n_item, n_entity, n_relation, train_data, eval_data, test_data, kg\n",
    "\n",
    "\n",
    "def load_rating(args):\n",
    "    print('reading rating file ...')\n",
    "\n",
    "    # reading rating file\n",
    "    rating_file = '../data/' + args.dataset + '/ratings_final'\n",
    "    if os.path.exists(rating_file + '.npy'):\n",
    "        rating_np = np.load(rating_file + '.npy')\n",
    "    else:\n",
    "        rating_np = np.loadtxt(rating_file + '.txt', dtype=np.int32)\n",
    "        np.save(rating_file + '.npy', rating_np)\n",
    "\n",
    "    n_user = len(set(rating_np[:, 0]))\n",
    "    n_item = len(set(rating_np[:, 1]))\n",
    "    train_data, eval_data, test_data = dataset_split(rating_np)\n",
    "\n",
    "    return n_user, n_item, train_data, eval_data, test_data\n",
    "\n",
    "\n",
    "def dataset_split(rating_np):\n",
    "    print('splitting dataset ...')\n",
    "\n",
    "    # train:eval:test = 6:2:2\n",
    "    eval_ratio = 0.2\n",
    "    test_ratio = 0.2\n",
    "    n_ratings = rating_np.shape[0]\n",
    "\n",
    "    eval_indices = np.random.choice(list(range(n_ratings)), size=int(n_ratings * eval_ratio), replace=False)\n",
    "    left = set(range(n_ratings)) - set(eval_indices)\n",
    "    test_indices = np.random.choice(list(left), size=int(n_ratings * test_ratio), replace=False)\n",
    "    train_indices = list(left - set(test_indices))\n",
    "\n",
    "    train_data = rating_np[train_indices]\n",
    "    eval_data = rating_np[eval_indices]\n",
    "    test_data = rating_np[test_indices]\n",
    "\n",
    "    return train_data, eval_data, test_data\n",
    "\n",
    "\n",
    "def load_kg(args):\n",
    "    print('reading KG file ...')\n",
    "\n",
    "    # reading kg file\n",
    "    kg_file = '../data/' + args.dataset + '/kg_final'\n",
    "    if os.path.exists(kg_file + '.npy'):\n",
    "        kg = np.load(kg_file + '.npy')\n",
    "    else:\n",
    "        kg = np.loadtxt(kg_file + '.txt', dtype=np.int32)\n",
    "        np.save(kg_file + '.npy', kg)\n",
    "\n",
    "    n_entity = len(set(kg[:, 0]) | set(kg[:, 2]))\n",
    "    n_relation = len(set(kg[:, 1]))\n",
    "\n",
    "    return n_entity, n_relation, kg\n",
    "\n",
    "data = load_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_record(data, is_train):\n",
    "    #建立每一个user交互过的item字典\n",
    "    user_history_dict = dict()\n",
    "    for interaction in data:\n",
    "        user = interaction[0]\n",
    "        item = interaction[1]\n",
    "        label = interaction[2]\n",
    "        if is_train or label == 1:\n",
    "            if user not in user_history_dict:\n",
    "                user_history_dict[user] = set()\n",
    "            user_history_dict[user].add(item)\n",
    "    return user_history_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_loss = False\n",
    "show_topk = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分解数据\n",
    "n_user, n_item, n_entity, n_relation = data[0], data[1], data[2], data[3]\n",
    "train_data, eval_data, test_data = data[4], data[5], data[6]\n",
    "kg = data[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossCompressUnit(nn.Module):\n",
    "    def __init__(self,dim,name=None):\n",
    "        super(CrossCompressUnit,self).__init__()\n",
    "        self.weight_vv = nn.Parameter(nn.init.kaiming_uniform_(torch.FloatTensor(dim,1)), requires_grad=True)\n",
    "        self.weight_ev = nn.Parameter(nn.init.kaiming_uniform_(torch.FloatTensor(dim,1)), requires_grad=True)\n",
    "        self.weight_ve = nn.Parameter(nn.init.kaiming_uniform_(torch.FloatTensor(dim,1)), requires_grad=True)\n",
    "        self.weight_ee = nn.Parameter(nn.init.kaiming_uniform_(torch.FloatTensor(dim,1)), requires_grad=True)\n",
    "        \n",
    "        self.bias_v = nn.Parameter(torch.FloatTensor(dim),requires_grad=True)\n",
    "        self.bias_e = nn.Parameter(torch.FloatTensor(dim),requires_grad=True)\n",
    "        \n",
    "        self.dim = dim\n",
    "    def forward(self,inputs):\n",
    "        \n",
    "        v,e = inputs\n",
    "        # [batch_size, dim, 1], [batch_size, 1, dim]\n",
    "        v = v.unsqueeze(2)\n",
    "        e = e.unsqueeze(1)\n",
    "        \n",
    "        # [batch_size, dim, dim]\n",
    "        c_matrix = v*e\n",
    "        c_matrix_transpose = c_matrix.permute([0,2,1])\n",
    "        \n",
    "        #[batch_size * dim, dim]\n",
    "        c_matrix = c_matrix.reshape([-1,self.dim])\n",
    "        c_matrix_transpose = c_matrix.reshape([-1,self.dim])\n",
    "        \n",
    "        v_output = c_matrix.mm(self.weight_vv) + c_matrix_transpose.mm(self.weight_ev)\n",
    "        v_output = v_output.reshape([-1,self.dim])\n",
    "        v_output = v_output+self.bias_v\n",
    "        \n",
    "        e_output = c_matrix.mm(self.weight_ve) + c_matrix_transpose.mm(self.weight_ee)\n",
    "        e_output = e_output.reshape([-1,self.dim])\n",
    "        e_output = e_output+self.bias_e\n",
    "        \n",
    "        return v_output,e_output\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_num = 100\n",
    "k_list = [1, 2, 5, 10, 20, 50, 100]\n",
    "#获取用户交互记录\n",
    "train_record = get_user_record(train_data, True)\n",
    "test_record = get_user_record(test_data, False)\n",
    "#全部用户列表\n",
    "user_list = list(set(train_record.keys()) & set(test_record.keys()))\n",
    "\n",
    "#取出100个用户\n",
    "if len(user_list) > user_num:\n",
    "    user_list = np.random.choice(user_list, size=user_num, replace=False)\n",
    "#取出全部item\n",
    "item_set = set(list(range(n_item)))\n",
    "\n",
    "class MKR_RS_Dataset(Dataset):\n",
    "    def __init__(self,train_dt):\n",
    "        super(MKR_RS_Dataset,self).__init__()\n",
    "        self.user_id = train_dt[:,0]\n",
    "        self.item_id = train_dt[:,1]\n",
    "        self.y = train_dt[:,2]\n",
    "        self.n = train_dt.shape[0]\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        return [torch.tensor(self.user_id[index],dtype=torch.long),\\\n",
    "                torch.tensor(self.item_id[index],dtype=torch.long),\\\n",
    "                torch.tensor(self.y[index],dtype=torch.long)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "    \n",
    "mkdr_rs_ds = MKR_RS_Dataset(train_data)\n",
    "mkdr_rs_dl = DataLoader(mkdr_rs_ds,batch_size=args.batch_size,shuffle=True)\n",
    "\n",
    "class MKR_KGE_Dataset(Dataset):\n",
    "    def __init__(self,kg_dt):\n",
    "        super(MKR_KGE_Dataset,self).__init__()\n",
    "        self.head_id = kg_dt[:,0]\n",
    "        self.relation_id = kg_dt[:,1]\n",
    "        self.tail_id = kg_dt[:,2]\n",
    "        self.n = kg_dt.shape[0]\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return [torch.tensor(self.head_id[index],dtype=torch.long),\\\n",
    "                torch.tensor(self.relation_id[index],dtype=torch.long),\\\n",
    "                torch.tensor(self.tail_id[index],dtype=torch.long)\n",
    "               ]\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "mkdr_kge_ds = MKR_KGE_Dataset(kg)\n",
    "mkdr_kge_dl = DataLoader(mkdr_kge_ds,batch_size=args.batch_size,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MKR_torch(nn.Module):\n",
    "    def __init__(self,args,n_users, n_items, n_entities, n_relations):\n",
    "        super(MKR_torch, self).__init__()\n",
    "        self._parse_args(n_users, n_items, n_entities, n_relations)\n",
    "        self._build_model(args)\n",
    "#         self._build_loss(args)\n",
    "#         self._build_train(args)\n",
    "        \n",
    "    def _parse_args(self, n_users, n_items, n_entities, n_relations):\n",
    "        self.n_user = n_users\n",
    "        self.n_item = n_items\n",
    "        self.n_entity = n_entities\n",
    "        self.n_relation = n_relations\n",
    "\n",
    "        # for computing l2 loss\n",
    "        self.vars_rs = []\n",
    "        self.vars_kge = []\n",
    "    \n",
    "    def forward_rs(self,user_indices,item_indices,head_indices,use_inner_product=True):\n",
    "        #batch_size,dim -> [4096,8]\n",
    "        self.user_embeddings = self.user_emb_matrix(user_indices)\n",
    "        self.item_embeddings = self.item_emb_matrix(item_indices)\n",
    "        self.head_embeddings = self.entity_emb_matrix(head_indices)\n",
    "\n",
    "#         for i in range(args.L):\n",
    "#             self.user_embeddings = self.user_mlp[i](self.user_embeddings)\n",
    "#             self.item_embeddings,self.head_embeddings = self.cc_unit[i]([self.item_embeddings,self.head_embeddings])\n",
    "        \n",
    "        if use_inner_product:\n",
    "            self.scores = torch.sum(self.user_embeddings*self.item_embeddings,axis=1)\n",
    "        else:\n",
    "            self.user_item_concat = torch.cat([self.user_embeddings,self.item_embeddings],axis=1)\n",
    "            for i in range(args.H-1):\n",
    "                self.user_item_concat=self.rs_mlps[i](self.user_item_concat)\n",
    "            self.scores = self.rs_pred_mlp(self.user_item_concat).squeeze()\n",
    "#         self.scores = torch.sigmoid(self.scores)\n",
    "        return self.scores\n",
    "    \n",
    "    def forward_kge(self,item_indices,head_indices,relation_indices,tail_indices):\n",
    "        self.item_embeddings = self.item_emb_matrix(item_indices)\n",
    "        self.head_embeddings = self.entity_emb_matrix(head_indices)\n",
    "        self.relation_embeddings = self.relation_emb_matrix(relation_indices)\n",
    "        self.tail_embeddings = self.entity_emb_matrix(tail_indices)\n",
    "        \n",
    "        for i in range(args.L):\n",
    "            self.relation_embeddings = self.rel_mlp[i](self.relation_embeddings)\n",
    "            \n",
    "        self.head_relation_concat = torch.cat([self.head_embeddings,self.relation_embeddings],axis=1)\n",
    "        for i in range(args.H-1):\n",
    "            self.head_realation_concat = self.kge_mlps[i](self.head_relation_concat)\n",
    "            \n",
    "        self.tail_pred = self.kge_pred_mlp(self.head_relation_concat)\n",
    "        self.tail_pred = torch.sigmoid(self.tail_pred)\n",
    "        #在这里直接计算损失\n",
    "        self.scores_kge = torch.sum(torch.sigmoid(torch.sum(self.tail_embeddings*self.tail_pred,axis=1)))\n",
    "        self.rmse=torch.mean(torch.sqrt(torch.sum((self.tail_embeddings-self.tail_pred)**2,axis=1)/args.dim))\n",
    "        self.base_loss_kge = -self.scores_kge\n",
    "        \n",
    "        #加入l2损失\n",
    "        self.l2_loss_kge = torch.sum(self.head_embeddings**2)/2 +torch.sum(self.tail_embeddings**2)/2\n",
    "        self.l2_loss_kge = self.l2_loss_kge*args.l2_weight\n",
    "        self.loss_kge = self.base_loss_kge + self.l2_loss_kge\n",
    "#         print(\"loss_kge\",self.loss_kge,\"base\",self.base_loss_kge,\"l2\",self.l2_loss_kge)\n",
    "        return self.loss_kge,self.rmse\n",
    "        \n",
    "    def _build_model(self,args):\n",
    "        self._build_low_layers(args)\n",
    "        self._build_high_layers(args)\n",
    "        \n",
    "    def _build_low_layers(self,args):\n",
    "        #Embedding构建\n",
    "        self.user_emb_matrix = nn.Embedding(self.n_user,args.dim)\n",
    "        self.item_emb_matrix = nn.Embedding(self.n_item,args.dim)\n",
    "        self.entity_emb_matrix = nn.Embedding(self.n_entity,args.dim)\n",
    "        self.relation_emb_matrix=  nn.Embedding(self.n_relation,args.dim)\n",
    "        \n",
    "        self.user_mlp=nn.ModuleList()\n",
    "        self.rel_mlp=nn.ModuleList()\n",
    "        self.cc_unit=nn.ModuleList()\n",
    "        \n",
    "        \n",
    "        for _ in range(args.L):\n",
    "            self.user_mlp.append(nn.Linear(args.dim,args.dim))\n",
    "            self.rel_mlp.append(nn.Linear(args.dim,args.dim))\n",
    "            self.cc_unit.append(CrossCompressUnit(args.dim))\n",
    "            \n",
    "    def _build_high_layers(self,args):\n",
    "        #RS\n",
    "        #拼接方法时过的mlp\n",
    "        self.rs_mlps = nn.ModuleList()\n",
    "        for _ in range(args.H-1):\n",
    "            rs_mlp = nn.Linear(args.dim*2, args.dim*2)\n",
    "            #[batch_size, dim*2]\n",
    "            self.rs_mlps.append(rs_mlp)\n",
    "        \n",
    "        self.rs_pred_mlp = nn.Linear(args.dim*2,1)\n",
    "        \n",
    "        #KGE\n",
    "        self.kge_mlps = nn.ModuleList()\n",
    "        for _ in range(args.H-1):\n",
    "            kge_mlp = nn.Linear(args.dim*2,args.dim*2)\n",
    "            self.kge_mlps.append(kge_mlp)\n",
    "            \n",
    "        self.kge_pred_mlp = nn.Linear(args.dim*2,args.dim)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MKR_torch(args,n_user,n_item,n_entity,n_relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(data,model):\n",
    "    model.eval()\n",
    "    mkdr_rs_ds = MKR_RS_Dataset(data)\n",
    "    mkdr_rs_dl = DataLoader(mkdr_rs_ds,batch_size=args.batch_size,shuffle=False)\n",
    "    auc_score_list = []\n",
    "    auc_label_list = []\n",
    "    acc_list = []\n",
    "    for i, data in enumerate(mkdr_rs_dl,0):\n",
    "        u_id,i_id,label = data\n",
    "        scores = model.forward_rs(u_id,i_id,i_id,False)\n",
    "        scores_norm = torch.sigmoid(scores).cpu().detach().numpy()\n",
    "        label = label.numpy()\n",
    "\n",
    "        predictions = [1 if i >= 0.5 else 0 for i in scores_norm]\n",
    "        auc_score_list = auc_score_list + list(scores_norm)\n",
    "        auc_label_list = auc_label_list + list(label)\n",
    "        \n",
    "        predictions = np.array(predictions)\n",
    "        \n",
    "#         auc = roc_auc_score(label,predictions)\n",
    "#         auc_list.append(auc)\n",
    "        \n",
    "        acc = np.mean(np.equal(predictions,label))\n",
    "        acc_list.append(acc)\n",
    "    auc = roc_auc_score(auc_label_list,auc_score_list)\n",
    "    return auc,np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7292, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-1627.8147, grad_fn=<AddBackward0>) tensor(1.0681, grad_fn=<MeanBackward0>)\n",
      "train:  0.5864700747388378 0.5721153846153846\n",
      "eval:  0.5752107943200705 0.5415162454873647\n",
      "test:  0.5689044958953159 0.5090252707581228\n",
      "\n",
      "tensor(0.6824, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1707.5049, grad_fn=<AddBackward0>) tensor(0.9792, grad_fn=<MeanBackward0>)\n",
      "train:  0.6669893588324554 0.6213942307692307\n",
      "eval:  0.6466853506452944 0.631768953068592\n",
      "test:  0.6408625062168946 0.5703971119133574\n",
      "\n",
      "tensor(0.6563, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1765.1741, grad_fn=<AddBackward0>) tensor(0.8908, grad_fn=<MeanBackward0>)\n",
      "train:  0.7346043703707628 0.6622596153846154\n",
      "eval:  0.6916160247186248 0.6245487364620939\n",
      "test:  0.6884024675062341 0.6245487364620939\n",
      "\n",
      "tensor(0.6193, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1833.0426, grad_fn=<AddBackward0>) tensor(0.8188, grad_fn=<MeanBackward0>)\n",
      "train:  0.788770384505844 0.7235576923076923\n",
      "eval:  0.7279340818079398 0.6570397111913358\n",
      "test:  0.728374213609542 0.6642599277978339\n",
      "\n",
      "tensor(0.5689, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1869.7832, grad_fn=<AddBackward0>) tensor(0.7439, grad_fn=<MeanBackward0>)\n",
      "train:  0.8264928350405418 0.7572115384615384\n",
      "eval:  0.7533388548673159 0.6895306859205776\n",
      "test:  0.7548493450831293 0.6931407942238267\n",
      "\n",
      "tensor(0.5203, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1911.0938, grad_fn=<AddBackward0>) tensor(0.6878, grad_fn=<MeanBackward0>)\n",
      "train:  0.8509092208591631 0.7836538461538461\n",
      "eval:  0.7674506687191156 0.6859205776173285\n",
      "test:  0.7692515712193725 0.7148014440433214\n",
      "\n",
      "tensor(0.4777, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1923.4694, grad_fn=<AddBackward0>) tensor(0.6369, grad_fn=<MeanBackward0>)\n",
      "train:  0.866545259389399 0.7920673076923077\n",
      "eval:  0.7723415765931578 0.7075812274368231\n",
      "test:  0.7748302407152583 0.7220216606498195\n",
      "\n",
      "tensor(0.4543, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1957.5212, grad_fn=<AddBackward0>) tensor(0.5914, grad_fn=<MeanBackward0>)\n",
      "train:  0.877213566051888 0.7956730769230769\n",
      "eval:  0.7722810906981673 0.703971119133574\n",
      "test:  0.7759955982322884 0.7184115523465704\n",
      "\n",
      "tensor(0.4465, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1969.8080, grad_fn=<AddBackward0>) tensor(0.5581, grad_fn=<MeanBackward0>)\n",
      "train:  0.8850058883520859 0.8064903846153846\n",
      "eval:  0.7700130787850394 0.7075812274368231\n",
      "test:  0.7736435514002639 0.7220216606498195\n",
      "\n",
      "tensor(0.4381, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1971.9724, grad_fn=<AddBackward0>) tensor(0.5303, grad_fn=<MeanBackward0>)\n",
      "train:  0.8909704933039649 0.8064903846153846\n",
      "eval:  0.7666639895592812 0.7184115523465704\n",
      "test:  0.770028745782857 0.7075812274368231\n",
      "\n",
      "tensor(0.4275, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1973.8232, grad_fn=<AddBackward0>) tensor(0.5112, grad_fn=<MeanBackward0>)\n",
      "train:  0.8956786345529113 0.8125\n",
      "eval:  0.7646359970551819 0.7148014440433214\n",
      "test:  0.7675416812178343 0.7111913357400722\n",
      "\n",
      "tensor(0.4190, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1974.7627, grad_fn=<AddBackward0>) tensor(0.4933, grad_fn=<MeanBackward0>)\n",
      "train:  0.8995187577620276 0.8112980769230769\n",
      "eval:  0.7622760432352843 0.7148014440433214\n",
      "test:  0.7650674436162936 0.7075812274368231\n",
      "\n",
      "tensor(0.4149, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1969.0189, grad_fn=<AddBackward0>) tensor(0.4789, grad_fn=<MeanBackward0>)\n",
      "train:  0.9025103714957969 0.8100961538461539\n",
      "eval:  0.7593516380550815 0.7111913357400722\n",
      "test:  0.7623447533090499 0.7148014440433214\n",
      "\n",
      "tensor(0.4000, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1966.8204, grad_fn=<AddBackward0>) tensor(0.4696, grad_fn=<MeanBackward0>)\n",
      "train:  0.9045422642345678 0.8173076923076923\n",
      "eval:  0.7580882385748865 0.703971119133574\n",
      "test:  0.7613304751140735 0.7111913357400722\n",
      "\n",
      "tensor(0.4096, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1955.3019, grad_fn=<AddBackward0>) tensor(0.4604, grad_fn=<MeanBackward0>)\n",
      "train:  0.906083400553768 0.8185096153846154\n",
      "eval:  0.7569896764046449 0.7003610108303249\n",
      "test:  0.7605654303964904 0.6967509025270758\n",
      "\n",
      "tensor(0.3954, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1956.7853, grad_fn=<AddBackward0>) tensor(0.4523, grad_fn=<MeanBackward0>)\n",
      "train:  0.9072664925983477 0.8221153846153846\n",
      "eval:  0.7564353757431761 0.703971119133574\n",
      "test:  0.759593955220959 0.6931407942238267\n",
      "\n",
      "tensor(0.3876, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1945.3406, grad_fn=<AddBackward0>) tensor(0.4475, grad_fn=<MeanBackward0>)\n",
      "train:  0.9082843984987855 0.8257211538461539\n",
      "eval:  0.7545950875079477 0.703971119133574\n",
      "test:  0.7577116540994028 0.6823104693140795\n",
      "\n",
      "tensor(0.3953, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1937.0092, grad_fn=<AddBackward0>) tensor(0.4438, grad_fn=<MeanBackward0>)\n",
      "train:  0.9085723550722313 0.8209134615384616\n",
      "eval:  0.7546783567022499 0.7075812274368231\n",
      "test:  0.7579988665425834 0.6750902527075813\n",
      "\n",
      "tensor(0.3778, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1932.1406, grad_fn=<AddBackward0>) tensor(0.4406, grad_fn=<MeanBackward0>)\n",
      "train:  0.9086818874364195 0.8125\n",
      "eval:  0.7549992470635478 0.703971119133574\n",
      "test:  0.7584763084311408 0.6750902527075813\n",
      "\n",
      "tensor(0.3876, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1931.1119, grad_fn=<AddBackward0>) tensor(0.4367, grad_fn=<MeanBackward0>)\n",
      "train:  0.9090456290669371 0.8100961538461539\n",
      "eval:  0.7539476179321576 0.7184115523465704\n",
      "test:  0.7575752421312435 0.7003610108303249\n",
      "\n",
      "tensor(0.3870, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1917.5317, grad_fn=<AddBackward0>) tensor(0.4378, grad_fn=<MeanBackward0>)\n",
      "train:  0.9094260445253165 0.8100961538461539\n",
      "eval:  0.7536039442715479 0.7148014440433214\n",
      "test:  0.757443096522677 0.7003610108303249\n",
      "\n",
      "tensor(0.3952, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1912.3689, grad_fn=<AddBackward0>) tensor(0.4369, grad_fn=<MeanBackward0>)\n",
      "train:  0.9095056433100169 0.8149038461538461\n",
      "eval:  0.7538788776227285 0.7003610108303249\n",
      "test:  0.7580852533531635 0.7075812274368231\n",
      "\n",
      "tensor(0.3819, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1907.0547, grad_fn=<AddBackward0>) tensor(0.4355, grad_fn=<MeanBackward0>)\n",
      "train:  0.9097620460118958 0.8161057692307693\n",
      "eval:  0.752881236823612 0.6967509025270758\n",
      "test:  0.7573796588228483 0.7003610108303249\n",
      "\n",
      "tensor(0.3708, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1899.7458, grad_fn=<AddBackward0>) tensor(0.4362, grad_fn=<MeanBackward0>)\n",
      "train:  0.9099704936447529 0.8257211538461539\n",
      "eval:  0.7524796707157915 0.6967509025270758\n",
      "test:  0.7564806002215829 0.6931407942238267\n",
      "\n",
      "tensor(0.3943, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1892.6161, grad_fn=<AddBackward0>) tensor(0.4356, grad_fn=<MeanBackward0>)\n",
      "train:  0.9099208377337585 0.8257211538461539\n",
      "eval:  0.7519571049314548 0.7003610108303249\n",
      "test:  0.756445967420182 0.6967509025270758\n",
      "\n",
      "tensor(0.3924, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1885.1854, grad_fn=<AddBackward0>) tensor(0.4371, grad_fn=<MeanBackward0>)\n",
      "train:  0.9096364501401892 0.8305288461538461\n",
      "eval:  0.7531039386942409 0.7075812274368231\n",
      "test:  0.7570420587209465 0.6931407942238267\n",
      "\n",
      "tensor(0.3991, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1880.8555, grad_fn=<AddBackward0>) tensor(0.4367, grad_fn=<MeanBackward0>)\n",
      "train:  0.9093169954604868 0.8269230769230769\n",
      "eval:  0.7535829457104931 0.7075812274368231\n",
      "test:  0.7586864196699143 0.7148014440433214\n",
      "\n",
      "tensor(0.3872, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1876.4089, grad_fn=<AddBackward0>) tensor(0.4369, grad_fn=<MeanBackward0>)\n",
      "train:  0.9095257405083337 0.8269230769230769\n",
      "eval:  0.7529845285502348 0.7111913357400722\n",
      "test:  0.758045155149931 0.7111913357400722\n",
      "\n",
      "tensor(0.3876, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-80710f37fa19>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#训练RS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmkdr_rs_dl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mu_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-4c4243712450>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     24\u001b[0m         return [torch.tensor(self.user_id[index],dtype=torch.long),\\\n\u001b[0;32m     25\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 torch.tensor(self.y[index],dtype=torch.long)]\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer_rs=torch.optim.Adam(model.parameters(),lr=args.lr_rs,weight_decay=1e-6)\n",
    "optimizer_kge=torch.optim.Adam(model.parameters(),lr=args.lr_kge,weight_decay=1e-6)\n",
    "\n",
    "for step in range(100): #args.n_epochs\n",
    "    start = 0\n",
    "    #训练RS\n",
    "    for i, data in enumerate(mkdr_rs_dl,0):\n",
    "        \n",
    "        u_id,i_id,label = data\n",
    "        optimizer_rs.zero_grad()\n",
    "\n",
    "        scores = model.forward_rs(u_id,i_id,i_id,use_inner_product=False) #[batch_size], 0-1的概率\n",
    "        rs_loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "        label = torch.tensor(label,dtype=torch.float32)\n",
    "\n",
    "        loss_rs = rs_loss_func(scores,label)\n",
    "        loss_rs.backward()\n",
    "        optimizer_rs.step()\n",
    "        if i%10 == 0:\n",
    "            print(loss_rs) \n",
    "        \n",
    "    #训练KGE\n",
    "    for i, data in enumerate(mkdr_kge_dl,0):\n",
    "        head_id,relation_id,tail_id = data\n",
    "        optimizer_kge.zero_grad()\n",
    "        \n",
    "        kge_loss,kge_rmse = model.forward_kge(head_id,head_id,relation_id,tail_id)\n",
    "    \n",
    "        kge_loss.backward()\n",
    "        optimizer_kge.step()\n",
    "    print(kge_loss,kge_rmse)  \n",
    "\n",
    "    #CTR评估\n",
    "    \n",
    "    train_auc, train_acc = eval_model(train_data,model)\n",
    "    print(\"train: \",train_auc,train_acc)\n",
    "    eval_auc,eval_acc = eval_model(eval_data,model)\n",
    "    print(\"eval: \",eval_auc,eval_acc)\n",
    "    test_auc,test_acc = eval_model(test_data,model)\n",
    "    print(\"test: \",test_auc,test_acc)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0067,  0.3157,  2.1031,  ..., -0.4541,  0.0270,  1.0726],\n",
       "        [ 0.6996,  1.1038, -1.1448,  ..., -0.4192, -0.2573, -0.1553],\n",
       "        [ 1.9460, -0.5554, -0.2630,  ...,  1.5448, -0.8065, -0.0257],\n",
       "        ...,\n",
       "        [ 2.4704,  2.3423,  0.0296,  ..., -0.2957,  0.1612,  1.1443],\n",
       "        [ 1.2935,  0.1242,  1.0175,  ...,  1.3341, -0.1081,  0.3238],\n",
       "        [ 0.5405,  1.5300, -1.2162,  ...,  1.6131,  0.5859,  0.0503]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.entity_emb_matrix.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-89-72214e887239>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-89-72214e887239>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    model.\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "       model.\n",
    "        def forward_rs(self,user_indices,item_indices,head_indices,use_inner_product=True):\n",
    "def forward_kge(self,item_indices,head_indices,realtion_indices):\n",
    "    \n",
    "    self,user_indices,item_indices,head_indices,relation_indices,tail_indices,user_inner_product=True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tail_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-02702a26203b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtail_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tail_pred' is not defined"
     ]
    }
   ],
   "source": [
    "tail_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([5178, 2711,  182,  ..., 1163, 4618, 2118], dtype=torch.int32), tensor([ 227,   90, 2305,  ...,  930, 1766, 1294], dtype=torch.int32), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.int32)]\n"
     ]
    }
   ],
   "source": [
    "for i in mkdr_dl:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3432661e-01 0.0000000e+00 9.9495560e-01 9.7256589e-01 5.2779913e-04\n",
      " 9.6741784e-01 1.7285347e-06 7.2866678e-05 9.9999821e-01 4.9482607e-03]\n"
     ]
    }
   ],
   "source": [
    "# tail_o = tf.random_normal([10,256])\n",
    "# tail_m = tf.random_normal([10,256])\n",
    "\n",
    "# r = tf.nn.sigmoid(tf.reduce_sum(tail_o*tail_m,axis=1))\n",
    "# with tf.Session() as sess:\n",
    "#     print(sess.run(r))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
